{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "print(device_lib.list_local_devices())\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some helpful functions for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_names():\n",
    "    out = []\n",
    "    f = open(\"Images/labels.txt\", \"r\")\n",
    "    for label in f:\n",
    "        out.append(label)\n",
    "    f.close()\n",
    "    return out\n",
    "\n",
    "def get_train(size):\n",
    "    f = open(\"Images/train.txt\", \"r\")\n",
    "    i=0\n",
    "    l=0\n",
    "    images = np.zeros((8126 , size[0] , size[1],3))\n",
    "    labels = []\n",
    "    for label in f:\n",
    "        img = label.split(\" \")\n",
    "        path = \"./\"+img[0]\n",
    "        im = Image.open(path)\n",
    "        im = im.crop((int(img[1]),int(img[2]),int(img[3]),int(img[4]))) \n",
    "        try:\n",
    "            image_data = np.array(im.resize(size))\n",
    "            images[i] = image_data\n",
    "            labels.append(int(img[5][:-1])-1)\n",
    "            i = i+1\n",
    "            l = l+1\n",
    "            im.close()\n",
    "        except:\n",
    "            im.close()\n",
    "            \n",
    "    f.close()\n",
    "    return images, labels\n",
    "\n",
    "def get_test(size):\n",
    "    f = open(\"Images/test.txt\", \"r\")\n",
    "    i=0\n",
    "    l=0\n",
    "    #8025\n",
    "    images = np.zeros((8025 , size[0] , size[1],3))\n",
    "    labels = []\n",
    "    for label in f:\n",
    "        img = label.split(\" \")\n",
    "        path = \"./\"+img[0]\n",
    "        im = Image.open(path)\n",
    "        im = im.crop((int(img[1]),int(img[2]),int(img[3]),int(img[4]))) \n",
    "        try:\n",
    "            image_data = np.array(im.resize(size))\n",
    "            images[i] = image_data\n",
    "            labels.append(int(img[5][:-1])-1)\n",
    "            i = i+1\n",
    "            l = l+1\n",
    "            im.close()\n",
    "        except:\n",
    "            im.close()\n",
    "            \n",
    "    f.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (224, 224)\n",
    "x_train, y_train = get_train(size)\n",
    "x_test, y_test = get_test(size)\n",
    "class_names = get_class_names()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, shear_range=0.2,zoom_range=0.2)\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size=24, seed=7)\n",
    "datagen2 = ImageDataGenerator(horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\n",
    "test_generator = datagen.flow(x_test, y_test, batch_size=24)\n",
    "x_train = 0\n",
    "x_test = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model - choose one of three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None, classes=1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.applications.mobilenet.MobileNet(input_shape=None, alpha=1.0, depth_multiplier=1, dropout=1e-3, include_top=True, weights=None, input_tensor=None, pooling=None, classes=196)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(size[0],size[1],3)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dense(196, activation='softmax'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning settings and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(filepath='files/epoch-{epoch:02d}_loss-{val_loss:.4f}.h5',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "tensotboard_callback = TensorBoard(log_dir='./logs', \n",
    "            histogram_freq=0, \n",
    "            batch_size=24, \n",
    "            write_graph=True, \n",
    "            write_grads=False, \n",
    "            write_images=False, \n",
    "            embeddings_freq=0, \n",
    "            embeddings_layer_names=None, \n",
    "            embeddings_metadata=None, \n",
    "            embeddings_data=None, \n",
    "            update_freq='batch')\n",
    "\n",
    "csv_logger = CSVLogger(filename='files/logs.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "\n",
    "callbacks = [model_checkpoint,\n",
    "             csv_logger,\n",
    "             tensotboard_callback]\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator, epochs = 70,steps_per_epoch = int(8126/24), callbacks = callbacks, shuffle=True, validation_data = test_generator, validation_steps = int(8025/24))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
